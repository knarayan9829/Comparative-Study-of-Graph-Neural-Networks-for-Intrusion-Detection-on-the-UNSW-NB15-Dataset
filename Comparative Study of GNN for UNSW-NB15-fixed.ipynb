{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "EnF2FB5gEjGu"
   },
   "outputs": [],
   "source": [
    "# Comparative Study of Graph Neural Networks for Intrusion Detection on the UNSW-NB15 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "g3rtmZguQoxC"
   },
   "outputs": [],
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "m63XoEZFRBNJ"
   },
   "outputs": [],
   "source": [
    "## Installing torch_geometric as a pre-requisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwGPbu1KRGZH",
    "outputId": "666d92f9-78f7-4093-eb58-4d565af446a0"
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "yFQ6Ot6gROMa"
   },
   "outputs": [],
   "source": [
    "## Importing pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64XqWd_FRIqt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "4sD8M_PZRam2"
   },
   "outputs": [],
   "source": [
    "## Loading the data and encoding categorical features after combining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZXTkjNaEwrw"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "test_df = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in ['proto', 'service', 'state', 'attack_cat']:\n",
    "    le = LabelEncoder()\n",
    "    combined_df[col] = le.fit_transform(combined_df[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "DzVUt70BdaHD"
   },
   "outputs": [],
   "source": [
    "## Splitting the dataset back to train_df and test_df and defining the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knWMsaIPUMQL"
   },
   "outputs": [],
   "source": [
    "# Split back into train and test sets\n",
    "train_df_encoded = combined_df.iloc[:len(train_df)]\n",
    "test_df_encoded = combined_df.iloc[len(train_df):]\n",
    "\n",
    "# Define features and labels\n",
    "features = [\n",
    "    'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes',\n",
    "    'rate', 'sttl', 'dttl', 'swin', 'dwin', 'trans_depth', 'sjit', 'djit',\n",
    "    'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
    "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src',\n",
    "    'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_ltm', 'ct_dst_src_ltm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "h_nyOfiXdiRQ"
   },
   "outputs": [],
   "source": [
    "## Visualizing the feature distribution and the correlation matrix for the features before processing, regularising and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xVR8MwZZTeFj",
    "outputId": "9ce4be36-870d-4047-9621-a6254a761b35"
   },
   "outputs": [],
   "source": [
    "# Reduce sample size if the dataset is large\n",
    "sampled_df = train_df_encoded.sample(n=10000, random_state=42) if len(train_df_encoded) > 10000 else train_df_encoded\n",
    "\n",
    "# Determine the number of rows and columns for subplots\n",
    "num_features = len(features)\n",
    "num_cols = 6\n",
    "num_rows = (num_features + num_cols - 1) // num_cols  # This ensures we have enough rows\n",
    "\n",
    "# Display data distribution for each feature\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 15))\n",
    "fig.suptitle('Feature Distribution')\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.histplot(sampled_df[feature], kde=True, ax=axes[i])\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Display correlation matrix\n",
    "corr_matrix = sampled_df[features].corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "qqBIbT8DdyMu"
   },
   "outputs": [],
   "source": [
    "## Defining features, label and using a standardize scaler to standardize the features and oversampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUk-4Sp0RmlE"
   },
   "outputs": [],
   "source": [
    "X_train = train_df_encoded[features]\n",
    "X_test = test_df_encoded[features]\n",
    "y_train = train_df_encoded['label']\n",
    "y_test = test_df_encoded['label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Oversample the minority class in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "PXExjCHedvYN"
   },
   "outputs": [],
   "source": [
    "## Visualizing the feature distribution and the correlation matrix for the features after processing, regularising and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M2YpDztyYuTA",
    "outputId": "f22f40eb-83ea-4ab6-ac34-2b220e234153"
   },
   "outputs": [],
   "source": [
    "# Data distribution after scaling and SMOTE\n",
    "num_features = len(features)\n",
    "num_cols = 6\n",
    "num_rows = (num_features + num_cols - 1) // num_cols  # Ensures enough rows\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 15))\n",
    "fig.suptitle('Feature Distribution After Processing')\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    sns.histplot(X_train_resampled[:, i], kde=True, ax=axes[i])\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Display correlation matrix after scaling\n",
    "X_train_resampled_df = pd.DataFrame(X_train_resampled, columns=features)\n",
    "corr_matrix = X_train_resampled_df.corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix After Processing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "I3h9FjIok78e"
   },
   "outputs": [],
   "source": [
    "## Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oE5SJ280k-PE"
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train_resampled.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "FwFvcgzok-pt"
   },
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHVh6oMhFFTW",
    "outputId": "b02ae64d-de87-403c-f393-a6a328257002"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def create_knn_edge_index(data, k=5):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
    "    distances, indices = nbrs.kneighbors(data)\n",
    "    row, col = [], []\n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in range(1, k):  # Start from 1 to avoid self-loop\n",
    "            row.append(i)\n",
    "            col.append(indices[i, j])\n",
    "    edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "def create_data_loader(X_tensor, y_tensor, batch_size=1024, k=5):\n",
    "    data_list = []\n",
    "    num_batches = len(X_tensor) // batch_size + (1 if len(X_tensor) % batch_size != 0 else 0)\n",
    "    for i in range(num_batches):\n",
    "        start_idx, end_idx = i * batch_size, min((i + 1) * batch_size, len(X_tensor))\n",
    "        X_batch, y_batch = X_tensor[start_idx:end_idx], y_tensor[start_idx:end_idx]\n",
    "        edge_index_batch = create_knn_edge_index(X_batch.numpy(), k=k)\n",
    "        data = Data(x=X_batch, edge_index=edge_index_batch, y=y_batch)\n",
    "        data_list.append(data)\n",
    "    return DataLoader(data_list, batch_size=1, shuffle=True)\n",
    "\n",
    "train_loader = create_data_loader(X_train_tensor, y_train_tensor, batch_size=1024, k=5)\n",
    "test_loader = create_data_loader(X_test_tensor, y_test_tensor, batch_size=1024, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Ua2SBSe54NXD"
   },
   "outputs": [],
   "source": [
    "## Creating a base GAT model that we will further improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYZIK5RLmSC9"
   },
   "outputs": [],
   "source": [
    "class CyberSecurityGATGridSearch(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.0):\n",
    "        super(CyberSecurityGATGridSearch, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.lin = nn.Linear(hidden_channels * heads, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "qUYiPYq34Rnx"
   },
   "outputs": [],
   "source": [
    "## Training and evaluating the model using different hidden channel sizes, heads, dropout values, learning rate to find the best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ar4W2zxSFIJd",
    "outputId": "080e236b-b2b1-4245-b73b-8ccfd21c2d5d"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "    model = CyberSecurityGATGridSearch(\n",
    "        in_channels=X_train_tensor.size(1),\n",
    "        hidden_channels=params['hidden_channels'],\n",
    "        out_channels=2,\n",
    "        heads=params['heads'],\n",
    "        dropout=params['dropout']\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{params['num_epochs']}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_channels': [32, 64, 128],\n",
    "    'heads': [1, 4, 8],\n",
    "    'dropout': [0.0, 0.3, 0.5],\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'num_epochs': [100]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "for hidden_channels in param_grid['hidden_channels']:\n",
    "    for heads in param_grid['heads']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            for learning_rate in param_grid['learning_rate']:\n",
    "                for num_epochs in param_grid['num_epochs']:\n",
    "                    params = {\n",
    "                        'hidden_channels': hidden_channels,\n",
    "                        'heads': heads,\n",
    "                        'dropout': dropout,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'num_epochs': num_epochs\n",
    "                    }\n",
    "                    print(f\"Training with params: {params}\")\n",
    "                    accuracy = train_and_evaluate(params)\n",
    "                    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_params = params\n",
    "\n",
    "print(\"Best Accuracy: \", best_accuracy)\n",
    "print(\"Best Params: \", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "jteTkMS04gRn"
   },
   "outputs": [],
   "source": [
    "## Adding all the obtained accuracies based on parameters to create a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8QERqFKkldb",
    "outputId": "45a8cecb-25e3-4bc0-de78-2e9f66a3b1b5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dictionaries containing the parameter sets and their corresponding accuracies\n",
    "data = [\n",
    "    {'hidden_channels': 32, 'heads': 1, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8776},\n",
    "    {'hidden_channels': 32, 'heads': 4, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8703},\n",
    "    {'hidden_channels': 32, 'heads': 4, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8722},\n",
    "    {'hidden_channels': 32, 'heads': 4, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8690},\n",
    "    {'hidden_channels': 32, 'heads': 4, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8704},\n",
    "    {'hidden_channels': 32, 'heads': 4, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8378},\n",
    "    {'hidden_channels': 32, 'heads': 4, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8382},\n",
    "    {'hidden_channels': 32, 'heads': 8, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8638},\n",
    "    {'hidden_channels': 32, 'heads': 8, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8465},\n",
    "    {'hidden_channels': 32, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8230},\n",
    "    {'hidden_channels': 32, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8519},\n",
    "    {'hidden_channels': 32, 'heads': 8, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8469},\n",
    "    {'hidden_channels': 32, 'heads': 8, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8663},\n",
    "    {'hidden_channels': 64, 'heads': 1, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8495},\n",
    "    {'hidden_channels': 64, 'heads': 1, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8483},\n",
    "    {'hidden_channels': 64, 'heads': 1, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.7952},\n",
    "    {'hidden_channels': 64, 'heads': 1, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8709},\n",
    "    {'hidden_channels': 64, 'heads': 1, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8216},\n",
    "    {'hidden_channels': 64, 'heads': 1, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8676},\n",
    "    {'hidden_channels': 64, 'heads': 4, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8513},\n",
    "    {'hidden_channels': 64, 'heads': 4, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8307},\n",
    "    {'hidden_channels': 64, 'heads': 4, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8490},\n",
    "    {'hidden_channels': 64, 'heads': 4, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8672},\n",
    "    {'hidden_channels': 64, 'heads': 4, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8275},\n",
    "    {'hidden_channels': 64, 'heads': 4, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8547},\n",
    "    {'hidden_channels': 64, 'heads': 8, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8680},\n",
    "    {'hidden_channels': 64, 'heads': 8, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8685},\n",
    "    {'hidden_channels': 64, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.9030},\n",
    "    {'hidden_channels': 64, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8715},\n",
    "    {'hidden_channels': 64, 'heads': 8, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8098},\n",
    "    {'hidden_channels': 64, 'heads': 8, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8613},\n",
    "    {'hidden_channels': 128, 'heads': 1, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8443},\n",
    "    {'hidden_channels': 128, 'heads': 1, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8644},\n",
    "    {'hidden_channels': 128, 'heads': 1, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8603},\n",
    "    {'hidden_channels': 128, 'heads': 1, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8924},\n",
    "    {'hidden_channels': 128, 'heads': 1, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.9027},\n",
    "    {'hidden_channels': 128, 'heads': 1, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8686},\n",
    "    {'hidden_channels': 128, 'heads': 4, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8400},\n",
    "    {'hidden_channels': 128, 'heads': 4, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8624},\n",
    "    {'hidden_channels': 128, 'heads': 4, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8383},\n",
    "    {'hidden_channels': 128, 'heads': 4, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8306},\n",
    "    {'hidden_channels': 128, 'heads': 4, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8499},\n",
    "    {'hidden_channels': 128, 'heads': 4, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8589},\n",
    "    {'hidden_channels': 128, 'heads': 8, 'dropout': 0.0, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8754},\n",
    "    {'hidden_channels': 128, 'heads': 8, 'dropout': 0.0, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8693},\n",
    "    {'hidden_channels': 128, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8580},\n",
    "    {'hidden_channels': 128, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8714},\n",
    "    {'hidden_channels': 128, 'heads': 8, 'dropout': 0.5, 'learning_rate': 0.001, 'num_s': 100, 'accuracy': 0.8121},\n",
    "    {'hidden_channels': 128, 'heads': 8, 'dropout': 0.5, 'learning_rate': 0.0001, 'num_s': 100, 'accuracy': 0.8391}\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "nqdZlU5x4oNd"
   },
   "outputs": [],
   "source": [
    "#Training the model with the best parameters for 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KH5aypkFLL6",
    "outputId": "cec73f87-199d-42ca-947c-c64361a08857"
   },
   "outputs": [],
   "source": [
    "best_params = {'hidden_channels': 64, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.001, 'num_s': 200}\n",
    "\n",
    "best_model = CyberSecurityGATGridSearch(\n",
    "    in_channels=X_train_tensor.size(1),\n",
    "    hidden_channels=best_params['hidden_channels'],\n",
    "    out_channels=2,\n",
    "    heads=best_params['heads'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    best_model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = best_model(data.x, data.edge_index)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "best_model.eval()\n",
    "correct, total = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        out = best_model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "        y_true.extend(data.y.cpu().numpy())\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "accuracy = correct / total\n",
    "print('Final Accuracy:', accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "NnYROu_f4vjR"
   },
   "outputs": [],
   "source": [
    "### Plotting a Precision-Recall Curve for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "crmYAVDDm8Zw",
    "outputId": "6f566930-8c7d-4c7f-fd38-b01021f3ed22"
   },
   "outputs": [],
   "source": [
    "# Plot Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Precision-Recall curve (area = {:.2f})'.format(pr_auc))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "KhkFK2La40Be"
   },
   "outputs": [],
   "source": [
    "### Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_OictXjWm-WA",
    "outputId": "b838cbc4-7476-43f8-af54-375d4917b72c"
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "YyT5AfKo424w"
   },
   "outputs": [],
   "source": [
    "## Exploring other models to understand how well our model works"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "9LJYV7zF5Boi"
   },
   "outputs": [],
   "source": [
    "### Creating an MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2G8Jao-5LmN"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "ohI75Y-D5QKn"
   },
   "outputs": [],
   "source": [
    "#### Training the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VJNX3R5q2X4",
    "outputId": "9c7543b6-03ce-4df9-8f04-a2a59c32d177"
   },
   "outputs": [],
   "source": [
    "mlp_model = MLP(input_dim=X_train_tensor.size(1), hidden_dim=64, output_dim=2)\n",
    "mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "mlp_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop for MLP model\n",
    "for epoch in range(100):\n",
    "    mlp_model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        mlp_optimizer.zero_grad()\n",
    "        out = mlp_model(data.x)\n",
    "        loss = mlp_criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        mlp_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation for MLP model\n",
    "mlp_model.eval()\n",
    "correct, total = 0, 0\n",
    "mlp_y_true, mlp_y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        out = mlp_model(data.x)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "        mlp_y_true.extend(data.y.cpu().numpy())\n",
    "        mlp_y_pred.extend(pred.cpu().numpy())\n",
    "mlp_accuracy = correct / total\n",
    "print('MLP Final Accuracy:', mlp_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Xt1jRbHn4-8n"
   },
   "outputs": [],
   "source": [
    "## Creating a GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jG19X-d5ae5"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.lin(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "g_kGbJ435cXQ"
   },
   "outputs": [],
   "source": [
    "### Training the created GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nr1PCx5hrAK8",
    "outputId": "2ea5c26c-083c-463f-90d5-1b3a7c4df318"
   },
   "outputs": [],
   "source": [
    "gcn_model = GCN(in_channels=X_train_tensor.size(1), hidden_channels=64, out_channels=2)\n",
    "gcn_optimizer = optim.Adam(gcn_model.parameters(), lr=0.001)\n",
    "gcn_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop for GCN model\n",
    "for epoch in range(100):\n",
    "    gcn_model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        gcn_optimizer.zero_grad()\n",
    "        out = gcn_model(data.x, data.edge_index)\n",
    "        loss = gcn_criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        gcn_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/100], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation for GCN model\n",
    "gcn_model.eval()\n",
    "correct, total = 0, 0\n",
    "gcn_y_true, gcn_y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        out = gcn_model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "        gcn_y_true.extend(data.y.cpu().numpy())\n",
    "        gcn_y_pred.extend(pred.cpu().numpy())\n",
    "gcn_accuracy = correct / total\n",
    "print('GCN Final Accuracy:', gcn_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "B86s7fHy5h5_"
   },
   "outputs": [],
   "source": [
    "## Comparison of all three models to determine which one performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_Mtp3TwRrQTZ",
    "outputId": "736aa756-bdb3-4cd5-c3ae-46fe111f186a"
   },
   "outputs": [],
   "source": [
    "# Compare the models\n",
    "print(f\"MLP Final Accuracy: {mlp_accuracy}\")\n",
    "print(f\"GCN Final Accuracy: {gcn_accuracy}\")\n",
    "print(f\"GAT Final Accuracy: {accuracy}\")\n",
    "\n",
    "# Print Classification Reports\n",
    "print(\"MLP Classification Report:\")\n",
    "print(classification_report(mlp_y_true, mlp_y_pred))\n",
    "\n",
    "print(\"GCN Classification Report:\")\n",
    "print(classification_report(gcn_y_true, gcn_y_pred))\n",
    "\n",
    "print(\"GAT Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Print Confusion Matrices\n",
    "print(\"MLP Confusion Matrix:\")\n",
    "print(confusion_matrix(mlp_y_true, mlp_y_pred))\n",
    "\n",
    "print(\"GCN Confusion Matrix:\")\n",
    "print(confusion_matrix(gcn_y_true, gcn_y_pred))\n",
    "\n",
    "print(\"GAT Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Plot Precision-Recall Curves\n",
    "def plot_precision_recall_curve(y_true, y_pred, model_name):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'{model_name} (AUC = {pr_auc:.2f})')\n",
    "\n",
    "plt.figure()\n",
    "plot_precision_recall_curve(mlp_y_true, mlp_y_pred, 'MLP')\n",
    "plot_precision_recall_curve(gcn_y_true, gcn_y_pred, 'GCN')\n",
    "plot_precision_recall_curve(y_true, y_pred, 'GAT')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrices\n",
    "def plot_confusion_matrix(cm, model_name):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(mlp_y_true, mlp_y_pred), 'MLP')\n",
    "plot_confusion_matrix(confusion_matrix(gcn_y_true, gcn_y_pred), 'GCN')\n",
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred), 'GAT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "H4sKt4Q55qp9"
   },
   "outputs": [],
   "source": [
    "### Results:\n",
    "\n",
    "\n",
    "\n",
    "1.   MLP Final Accuracy: 0.8517289167964138\n",
    "2.   GCN Final Accuracy: 0.8754883341602934\n",
    "3.   GAT Final Accuracy: 0.8524646260714835\n",
    "\n",
    "From this we infer that GAT does perform better than the MLP model but not better than the GCN model, we perform further analysis to create a more advanced GAT model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "EJr7b5VG6CGd"
   },
   "outputs": [],
   "source": [
    "## Creating an advanced GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ib7nxWCV1mZb"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, LayerNorm\n",
    "\n",
    "class AdvancedGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.0):\n",
    "        super(AdvancedGAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.norm1 = LayerNorm(hidden_channels * heads)\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_channels * heads)  # Linear layer for residual connection\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.norm2 = LayerNorm(hidden_channels * heads)\n",
    "        self.lin2 = nn.Linear(hidden_channels * heads, hidden_channels * heads)  # Linear layer for residual connection\n",
    "        self.fc = nn.Linear(hidden_channels * heads, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.lin1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(self.norm1(x))\n",
    "        x = self.dropout(x)\n",
    "        x += residual  # Add residual connection\n",
    "\n",
    "        residual = self.lin2(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(self.norm2(x))\n",
    "        x = self.dropout(x)\n",
    "        x += residual  # Add residual connection\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "W1vTbRS26QOX"
   },
   "outputs": [],
   "source": [
    "### Setting the best parameters obtained earlier and declaring the optimizer and the criterion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaEDFbtm6Jgv"
   },
   "outputs": [],
   "source": [
    "# Instantiate the advanced GAT model\n",
    "best_params = {'hidden_channels': 128, 'heads': 8, 'dropout': 0.3, 'learning_rate': 0.0001, 'num_epochs': 100}\n",
    "advanced_gat_model = AdvancedGAT(\n",
    "    in_channels=X_train_tensor.size(1),\n",
    "    hidden_channels=best_params['hidden_channels'],\n",
    "    out_channels=2,\n",
    "    heads=best_params['heads'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(advanced_gat_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "TyZb2TWf6doh"
   },
   "outputs": [],
   "source": [
    "### Training the Advanced GAT for 100 epochs, evaluating the same and giving the final accuracy, classification report and the confusion matrix for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y54RR4M96Y3Z",
    "outputId": "76cbda7c-fdf3-469a-d990-8b9a91409746"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(best_params['num_epochs']):\n",
    "    advanced_gat_model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = advanced_gat_model(data.x, data.edge_index)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{best_params['num_epochs']}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation Loop\n",
    "advanced_gat_model.eval()\n",
    "correct, total = 0, 0\n",
    "agat_y_true, agat_y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        out = advanced_gat_model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "        agat_y_true.extend(data.y.cpu().numpy())\n",
    "        agat_y_pred.extend(pred.cpu().numpy())\n",
    "agat_accuracy = correct / total\n",
    "print('Advanced GAT Final Accuracy:', agat_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(agat_y_true, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(agat_y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "VTjsumQX6p4H",
    "outputId": "8d77de3a-6bc3-462e-e4b2-310861280886"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(agat_y_true, agat_y_pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Precision-Recall curve (area = {:.2f})'.format(pr_auc))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "hboV2C3e6w4a",
    "outputId": "44ab1553-c7e4-4c8b-f5b4-20234faba06e"
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "uuED1BJhV2WX"
   },
   "outputs": [],
   "source": [
    "# Ablation Studies:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "0x67Z9hdZAB-"
   },
   "outputs": [],
   "source": [
    "##Advanced GAT model without Residual Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "kFalSM4RZL-V"
   },
   "outputs": [],
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmUKrEDeZLuS"
   },
   "outputs": [],
   "source": [
    "# Define the Advanced GAT model without Residual Connections\n",
    "class AdvancedGATNoResidual(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.0):\n",
    "        super(AdvancedGATNoResidual, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.norm1 = LayerNorm(hidden_channels * heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.norm2 = LayerNorm(hidden_channels * heads)\n",
    "        self.fc = nn.Linear(hidden_channels * heads, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(self.norm1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(self.norm2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "G8UhA_ISZd4t"
   },
   "outputs": [],
   "source": [
    "### Setting best parameters found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcAedFv_ZKlQ"
   },
   "outputs": [],
   "source": [
    "# Instantiate the ablated models\n",
    "advanced_gat_no_residual = AdvancedGATNoResidual(\n",
    "    in_channels=X_train_tensor.size(1),\n",
    "    hidden_channels=128,\n",
    "    out_channels=2,\n",
    "    heads=8,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "iQ5hdY0DZhr3"
   },
   "outputs": [],
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sc1FepnFY_iQ",
    "outputId": "49b4fe13-1489-433b-dd53-50954a29dda0"
   },
   "outputs": [],
   "source": [
    "advanced_gat_no_residual_accuracy, advanced_gat_no_residual_y_true, advanced_gat_no_residual_y_pred, advanced_gat_no_residual_losses = train_and_evaluate(advanced_gat_no_residual, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "SiQGFksHZkpL"
   },
   "outputs": [],
   "source": [
    "## Advanced GAT model without Normalization Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQWm-j6rZxjj"
   },
   "outputs": [],
   "source": [
    "# Define the Advanced GAT model without Layer Normalization\n",
    "class AdvancedGATNoLayerNorm(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.0):\n",
    "        super(AdvancedGATNoLayerNorm, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_channels * heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.lin2 = nn.Linear(hidden_channels * heads, hidden_channels * heads)\n",
    "        self.fc = nn.Linear(hidden_channels * heads, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.lin1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        residual = self.lin2(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "5b4_MNrNZ4LW"
   },
   "outputs": [],
   "source": [
    "### Setting best parameters found previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M6JUwFiZxZI"
   },
   "outputs": [],
   "source": [
    "advanced_gat_no_layer_norm = AdvancedGATNoLayerNorm(\n",
    "    in_channels=X_train_tensor.size(1),\n",
    "    hidden_channels=128,\n",
    "    out_channels=2,\n",
    "    heads=8,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "mcZNGwDvZ6P2"
   },
   "outputs": [],
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-9wa4MMV2CI",
    "outputId": "b09b6868-d933-4f95-96f2-3528744b93ff"
   },
   "outputs": [],
   "source": [
    "advanced_gat_no_layer_norm_accuracy, advanced_gat_no_layer_norm_y_true, advanced_gat_no_layer_norm_y_pred, advanced_gat_no_layer_norm_losses = train_and_evaluate(advanced_gat_no_layer_norm, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "tNjN4oyzaIUz"
   },
   "outputs": [],
   "source": [
    "## Comparison between the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e6mJXo0oaHjm",
    "outputId": "422d3591-ac6c-4e0e-f614-a4658018064e"
   },
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(advanced_gat_no_residual_losses, label='No Residual Connections')\n",
    "plt.plot(advanced_gat_no_layer_norm_losses, label='No Layer Normalization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(f\"No Residual Connections Accuracy: {advanced_gat_no_residual_accuracy}\")\n",
    "print(f\"No Layer Normalization Accuracy: {advanced_gat_no_layer_norm_accuracy}\")\n",
    "\n",
    "print(\"No Residual Connections Classification Report:\")\n",
    "print(classification_report(advanced_gat_no_residual_y_true, advanced_gat_no_residual_y_pred))\n",
    "\n",
    "print(\"No Layer Normalization Classification Report:\")\n",
    "print(classification_report(advanced_gat_no_layer_norm_y_true, advanced_gat_no_layer_norm_y_pred))\n",
    "\n",
    "# Plot confusion matrices\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(advanced_gat_no_residual_y_true, advanced_gat_no_residual_y_pred), 'No Residual Connections Confusion Matrix')\n",
    "plot_confusion_matrix(confusion_matrix(advanced_gat_no_layer_norm_y_true, advanced_gat_no_layer_norm_y_pred), 'No Layer Normalization Confusion Matrix')\n",
    "\n",
    "# Report the accuracies\n",
    "print(f\"Advanced GAT No Residual Connections Accuracy: {advanced_gat_no_residual_accuracy:.4f}\")\n",
    "print(f\"Advanced GAT No Layer Normalization Accuracy: {advanced_gat_no_layer_norm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "dU4JDYSYVvk7"
   },
   "outputs": [],
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "nQhlr2mfSLl8"
   },
   "outputs": [],
   "source": [
    "## Visualization for all model architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qDt5lrs-SQm2",
    "outputId": "93ababb4-7f9f-4548-b6f0-1100290c81cc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def draw_graph(G, pos, labels=None, title=None, node_color='skyblue', node_size=3000, edge_color='gray', font_size=12, font_color='black', font_weight='bold'):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    if title:\n",
    "        plt.title(title, fontsize=16)\n",
    "    nx.draw(G, pos, with_labels=True, labels=labels, node_color=node_color, node_size=node_size, edge_color=edge_color, font_size=font_size, font_color=font_color, font_weight=font_weight)\n",
    "    plt.show()\n",
    "\n",
    "# MLP Architecture\n",
    "def visualize_mlp():\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([('Input Layer', 'Hidden Layer 1'),\n",
    "                      ('Hidden Layer 1', 'Hidden Layer 2'),\n",
    "                      ('Hidden Layer 2', 'Output Layer')])\n",
    "    pos = {'Input Layer': (0, 3), 'Hidden Layer 1': (1, 2), 'Hidden Layer 2': (2, 1), 'Output Layer': (3, 0)}\n",
    "    labels = {'Input Layer': 'Input Layer\\n(31 nodes)', 'Hidden Layer 1': 'Hidden Layer 1\\n(64 nodes)',\n",
    "              'Hidden Layer 2': 'Hidden Layer 2\\n(64 nodes)', 'Output Layer': 'Output Layer\\n(2 nodes)'}\n",
    "    draw_graph(G, pos, labels, title=\"MLP Architecture\")\n",
    "\n",
    "# GCN Architecture\n",
    "def visualize_gcn():\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([('Input Layer', 'GCN Layer 1'),\n",
    "                      ('GCN Layer 1', 'ReLU 1'),\n",
    "                      ('ReLU 1', 'GCN Layer 2'),\n",
    "                      ('GCN Layer 2', 'ReLU 2'),\n",
    "                      ('ReLU 2', 'Fully Connected Layer'),\n",
    "                      ('Fully Connected Layer', 'Output Layer')])\n",
    "    pos = {'Input Layer': (0, 5), 'GCN Layer 1': (1, 4), 'ReLU 1': (2, 3), 'GCN Layer 2': (3, 2),\n",
    "           'ReLU 2': (4, 1), 'Fully Connected Layer': (5, 0), 'Output Layer': (6, -1)}\n",
    "    labels = {'Input Layer': 'Input Layer\\n(31 nodes)', 'GCN Layer 1': 'GCN Layer 1', 'ReLU 1': 'ReLU Activation',\n",
    "              'GCN Layer 2': 'GCN Layer 2', 'ReLU 2': 'ReLU Activation', 'Fully Connected Layer': 'Fully Connected Layer',\n",
    "              'Output Layer': 'Output Layer\\n(2 nodes)'}\n",
    "    draw_graph(G, pos, labels, title=\"GCN Architecture\")\n",
    "\n",
    "# GAT Architecture\n",
    "def visualize_gat():\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([('Input Layer', 'GAT Layer 1'),\n",
    "                      ('GAT Layer 1', 'ReLU 1'),\n",
    "                      ('ReLU 1', 'GAT Layer 2'),\n",
    "                      ('GAT Layer 2', 'ReLU 2'),\n",
    "                      ('ReLU 2', 'Fully Connected Layer'),\n",
    "                      ('Fully Connected Layer', 'Output Layer')])\n",
    "    pos = {'Input Layer': (0, 5), 'GAT Layer 1': (1, 4), 'ReLU 1': (2, 3), 'GAT Layer 2': (3, 2),\n",
    "           'ReLU 2': (4, 1), 'Fully Connected Layer': (5, 0), 'Output Layer': (6, -1)}\n",
    "    labels = {'Input Layer': 'Input Layer\\n(31 nodes)', 'GAT Layer 1': 'GAT Layer 1\\n(4 heads)', 'ReLU 1': 'ReLU Activation',\n",
    "              'GAT Layer 2': 'GAT Layer 2\\n(4 heads)', 'ReLU 2': 'ReLU Activation', 'Fully Connected Layer': 'Fully Connected Layer',\n",
    "              'Output Layer': 'Output Layer\\n(2 nodes)'}\n",
    "    draw_graph(G, pos, labels, title=\"GAT Architecture\")\n",
    "\n",
    "# Advanced GAT Architecture\n",
    "def visualize_advanced_gat():\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([('Input Layer', 'Residual Connection 1'),\n",
    "                      ('Residual Connection 1', 'GAT Layer 1'),\n",
    "                      ('GAT Layer 1', 'ReLU 1'),\n",
    "                      ('ReLU 1', 'Layer Normalization 1'),\n",
    "                      ('Layer Normalization 1', 'Dropout 1'),\n",
    "                      ('Dropout 1', 'Residual Connection 2'),\n",
    "                      ('Residual Connection 2', 'GAT Layer 2'),\n",
    "                      ('GAT Layer 2', 'ReLU 2'),\n",
    "                      ('ReLU 2', 'Layer Normalization 2'),\n",
    "                      ('Layer Normalization 2', 'Dropout 2'),\n",
    "                      ('Dropout 2', 'Fully Connected Layer'),\n",
    "                      ('Fully Connected Layer', 'Output Layer')])\n",
    "    pos = {'Input Layer': (0, 11), 'Residual Connection 1': (1, 10), 'GAT Layer 1': (2, 9), 'ReLU 1': (3, 8),\n",
    "           'Layer Normalization 1': (4, 7), 'Dropout 1': (5, 6), 'Residual Connection 2': (6, 5), 'GAT Layer 2': (7, 4),\n",
    "           'ReLU 2': (8, 3), 'Layer Normalization 2': (9, 2), 'Dropout 2': (10, 1), 'Fully Connected Layer': (11, 0), 'Output Layer': (12, -1)}\n",
    "    labels = {'Input Layer': 'Input Layer\\n(31 nodes)', 'Residual Connection 1': 'Residual Connection 1', 'GAT Layer 1': 'GAT Layer 1\\n(8 heads)',\n",
    "              'ReLU 1': 'ReLU Activation', 'Layer Normalization 1': 'Layer Normalization', 'Dropout 1': 'Dropout', 'Residual Connection 2': 'Residual Connection 2',\n",
    "              'GAT Layer 2': 'GAT Layer 2\\n(8 heads)', 'ReLU 2': 'ReLU Activation', 'Layer Normalization 2': 'Layer Normalization', 'Dropout 2': 'Dropout',\n",
    "              'Fully Connected Layer': 'Fully Connected Layer', 'Output Layer': 'Output Layer\\n(2 nodes)'}\n",
    "    draw_graph(G, pos, labels, title=\"Advanced GAT Architecture\")\n",
    "\n",
    "# Visualize the model architectures\n",
    "visualize_mlp()\n",
    "visualize_gcn()\n",
    "visualize_gat()\n",
    "visualize_advanced_gat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "_kEZHY7L65yr"
   },
   "outputs": [],
   "source": [
    "# Final comparison of all four models with reports and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nwzNnhav60jb",
    "outputId": "14df3e1b-e69e-45ca-a3e5-4f8b95f202b7"
   },
   "outputs": [],
   "source": [
    "# Compare the models\n",
    "print(f\"MLP Final Accuracy: {mlp_accuracy}\")\n",
    "print(f\"GCN Final Accuracy: {gcn_accuracy}\")\n",
    "print(f\"GAT Final Accuracy: {accuracy}\")\n",
    "print(f\"Advanced GAT Final Accuracy: {agat_accuracy}\")\n",
    "\n",
    "# Print Classification Reports\n",
    "print(\"MLP Classification Report:\")\n",
    "print(classification_report(mlp_y_true, mlp_y_pred))\n",
    "\n",
    "print(\"GCN Classification Report:\")\n",
    "print(classification_report(gcn_y_true, gcn_y_pred))\n",
    "\n",
    "print(\"GAT Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"Advanced GAT Classification Report:\")\n",
    "print(classification_report(agat_y_true, agat_y_pred))\n",
    "\n",
    "# Print Confusion Matrices\n",
    "print(\"MLP Confusion Matrix:\")\n",
    "print(confusion_matrix(mlp_y_true, mlp_y_pred))\n",
    "\n",
    "print(\"GCN Confusion Matrix:\")\n",
    "print(confusion_matrix(gcn_y_true, gcn_y_pred))\n",
    "\n",
    "print(\"GAT Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"Advanced GAT Confusion Matrix:\")\n",
    "print(confusion_matrix(agat_y_true, agat_y_pred))\n",
    "\n",
    "# Plot Precision-Recall Curves for all models\n",
    "def plot_precision_recall_curve(y_true, y_pred, model_name):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'{model_name} (AUC = {pr_auc:.2f})')\n",
    "\n",
    "plt.figure()\n",
    "plot_precision_recall_curve(mlp_y_true, mlp_y_pred, 'MLP')\n",
    "plot_precision_recall_curve(gcn_y_true, gcn_y_pred, 'GCN')\n",
    "plot_precision_recall_curve(y_true, y_pred, 'GAT')\n",
    "plot_precision_recall_curve(agat_y_true, agat_y_pred, 'Advanced GAT')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrices for all models\n",
    "def plot_confusion_matrix(cm, model_name):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(mlp_y_true, mlp_y_pred), 'MLP')\n",
    "plot_confusion_matrix(confusion_matrix(gcn_y_true, gcn_y_pred), 'GCN')\n",
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred), 'GAT')\n",
    "plot_confusion_matrix(confusion_matrix(agat_y_true, agat_y_pred), 'Advanced GAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "qhdwvrk0GNEe"
   },
   "outputs": [],
   "source": [
    "In this report, we compared the performance of various models including MLP, GCN, GAT, and an advanced GAT model on a network intrusion detection task using the UNSW-NB15 dataset. The evaluation metrics used included accuracy, precision, recall, and F1-score, along with confusion matrices and precision-recall curves to visualize the performance.\n",
    "\n",
    "### Model Performances:\n",
    "\n",
    "#### MLP (Multilayer Perceptron)\n",
    "- **Final Accuracy**: 0.8517\n",
    "- **Precision-Recall AUC**: 0.96\n",
    "- **Classification Report**:\n",
    "  - Precision: 0.69 (Class 0), 0.99 (Class 1)\n",
    "  - Recall: 0.98 (Class 0), 0.79 (Class 1)\n",
    "  - F1-Score: 0.81 (Class 0), 0.88 (Class 1)\n",
    "- **Confusion Matrix**:\n",
    "  - True Positives (Class 0): 54791\n",
    "  - False Positives (Class 0): 1209\n",
    "  - True Positives (Class 1): 94552\n",
    "  - False Positives (Class 1): 24789\n",
    "\n",
    "#### GCN (Graph Convolutional Network)\n",
    "- **Final Accuracy**: 0.8755\n",
    "- **Precision-Recall AUC**: 0.96\n",
    "- **Classification Report**:\n",
    "  - Precision: 0.73 (Class 0), 0.98 (Class 1)\n",
    "  - Recall: 0.97 (Class 0), 0.83 (Class 1)\n",
    "  - F1-Score: 0.83 (Class 0), 0.90 (Class 1)\n",
    "- **Confusion Matrix**:\n",
    "  - True Positives (Class 0): 54051\n",
    "  - False Positives (Class 0): 1949\n",
    "  - True Positives (Class 1): 99458\n",
    "  - False Positives (Class 1): 19883\n",
    "\n",
    "#### GAT (Graph Attention Network)\n",
    "- **Final Accuracy**: 0.8896\n",
    "- **Precision-Recall AUC**: 0.97\n",
    "- **Classification Report**:\n",
    "  - Precision: 0.76 (Class 0), 0.98 (Class 1)\n",
    "  - Recall: 0.96 (Class 0), 0.86 (Class 1)\n",
    "  - F1-Score: 0.85 (Class 0), 0.91 (Class 1)\n",
    "- **Confusion Matrix**:\n",
    "  - True Positives (Class 0): 53520\n",
    "  - False Positives (Class 0): 2480\n",
    "  - True Positives (Class 1): 102460\n",
    "  - False Positives (Class 1): 16881\n",
    "\n",
    "#### Advanced GAT (with Residual Connections and Layer Normalization)\n",
    "- **Final Accuracy**: 0.9261\n",
    "- **Precision-Recall AUC**: 0.97\n",
    "- **Classification Report**:\n",
    "  - Precision: 0.86 (Class 0), 0.96 (Class 1)\n",
    "  - Recall: 0.91 (Class 0), 0.93 (Class 1)\n",
    "  - F1-Score: 0.89 (Class 0), 0.95 (Class 1)\n",
    "- **Confusion Matrix**:\n",
    "  - True Positives (Class 0): 51127\n",
    "  - False Positives (Class 0): 4873\n",
    "  - True Positives (Class 1): 111264\n",
    "  - False Positives (Class 1): 8077\n",
    "\n",
    "### Conclusion and Insights:\n",
    "\n",
    "#### Model Comparison:\n",
    "- The Advanced GAT model outperformed all other models with a final accuracy of 0.9261 and high precision, recall, and F1-scores for both classes.\n",
    "- The GCN model performed better than the MLP model, showcasing the advantage of utilizing graph-based learning for this task.\n",
    "- The GAT model showed improvement over the GCN and MLP models, indicating the benefit of attention mechanisms in graph learning.\n",
    "\n",
    "#### Performance Analysis:\n",
    "- The confusion matrices and precision-recall curves reveal that the Advanced GAT model has the best performance in correctly classifying both normal and attack classes with fewer false positives and false negatives compared to other models.\n",
    "- The Precision-Recall AUC values of 0.97 for both the GAT and Advanced GAT models demonstrate their effectiveness in handling imbalanced datasets by maintaining high precision and recall.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
