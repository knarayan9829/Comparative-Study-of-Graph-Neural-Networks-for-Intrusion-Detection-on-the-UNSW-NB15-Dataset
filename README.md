# Comparative Study of Graph Neural Networks for Intrusion Detection on the UNSW-NB15 Dataset

This project presents a comparative analysis of MLP, GCN, GAT, and an advanced GAT model on the UNSW-NB15 cybersecurity dataset. It applies graph-based learning techniques for detecting anomalous network activity using node-level classification and feature engineering.

## ğŸŒŸ Objective

To evaluate and compare the performance of Graph Neural Network models on the UNSW-NB15 dataset, specifically for intrusion detection using metrics like accuracy, precision, recall, and F1-score.

## ğŸ“Š Models Compared

### âœ… MLP (Multilayer Perceptron)

Acts as a baseline non-graph neural model.

Performance used to benchmark GNN effectiveness.

### âœ… GCN (Graph Convolutional Network)

Learns via neighborhood aggregation from a constructed KNN graph.

Demonstrates improved structural learning over MLP.

### âœ… GAT (Graph Attention Network)

Incorporates attention mechanisms to assign learnable weights to neighbor nodes.

Offers interpretability and finer control.

### âœ… Advanced GAT

Includes enhancements like:

Residual connections

Batch normalization

Deeper architecture

Outperforms standard GAT in precision and recall.

## ğŸ§ª Dataset

UNSW-NB15: A modern benchmark dataset for intrusion detection.

Features: 49 attributes (both categorical and numerical).

Preprocessing includes:

Label encoding of categorical features

Standardization using StandardScaler

SMOTE for oversampling the minority class

## ğŸ”§ Setup & Installation

### ğŸ“¦ Requirements

Python 3.8+

PyTorch

PyTorch Geometric

Scikit-learn

Pandas, Matplotlib, Seaborn

Install all dependencies:

pip install -r requirements.txt

## ğŸš€ How to Run

### Launch the notebook
jupyter notebook "Comparative Study of GNN for UNSW-NB15.ipynb"

Follow the sequential cells to:

Load and preprocess the data

Create graph representations

Train and evaluate MLP, GCN, GAT, and Advanced GAT

Visualise results

## ğŸ“ˆ Results Summary

Model

Accuracy

MLP

0.8517

GCN

0.8754

GAT

0.8524

Advanced GAT

### âœ… Best performance (improved precision/recall)

Conclusion: Advanced GAT outperforms standard GAT and MLP, and rivals or surpasses GCN in overall classification metrics.

## ğŸ”¬ Ablation Studies

The impact of each architectural enhancement on GAT was tested:

GAT w/o Residual Connections

GAT w/o Normalization Layers

These were evaluated independently to quantify their influence on model robustness.

## ğŸ“ Project Structure

.
â”œâ”€â”€ Comparative Study of GNN for UNSW-NB15.ipynb  # Main notebook
â”œâ”€â”€ README.md                                     # Project documentation

## ğŸ“Š Visualizations

Correlation heatmaps before and after preprocessing

Feature distributions

Precision-Recall curves

Confusion matrices

Attention visualizations for GAT models

## ğŸ¤ Contributing

Contributions and improvements are welcome via pull requests.

ğŸ“œ License

This project is licensed under the MIT License.
